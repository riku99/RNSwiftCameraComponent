import UIKit
import AVFoundation
import Foundation

@objc(CameraView)
class CameraView: UIView {
  var captureSession = AVCaptureSession()
  var mainCamera: AVCaptureDevice?
  var innerCamera: AVCaptureDevice?
  var currentDevice: AVCaptureDevice?
  var photoOutput: AVCapturePhotoOutput?
  var cameraPreviewLayer: AVCaptureVideoPreviewLayer?
  
  @objc var flash = false
  
  override public init(frame: CGRect) {
    super.init(frame: frame)
    setupCaptureSession()
    setupDevice()
    setupInputOutput()
    setupPreviewLayer()
    captureSession.startRunning()
  }
  
  // PropsãŒå…¨ã¦ã‚»ãƒƒãƒˆã•ã‚Œã¦ã‹ã‚‰å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã€‚RCTViewã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹
  // RCTViewManagerã®view()ãŒ return [RCTView new]; ã¨ãªã£ã¦ã‚‹ã‹ã‚‰ã€RCTViewManagerã‚’ç¶™æ‰¿ã—ã¦ã„ã‚‹ã‚¯ãƒ©ã‚¹ã®view()ã§returnã•ã‚Œã¦ã„ã‚‹UIViewã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã§ãã‚‹
  override func didSetProps(_ changedProps: [String]!) {
    print("ğŸ˜„ flash is " + String(flash))
  }
  
  @objc
  func capture() {
    let settings = AVCapturePhotoSettings()
    settings.flashMode = flash ? .on : .off
    self.photoOutput?.capturePhoto(with: settings, delegate: self as AVCapturePhotoCaptureDelegate)
  }
  
  func setupPreviewLayer() {
    // frameã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–å´ã§æŒ‡å®šã—ãªã„ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»é¢è¡¨ç¤ºã•ã‚Œãªã„(?)
    self.frame = CGRect(x: 0, y: 0, width: UIScreen.main.bounds.size.width, height: UIScreen.main.bounds.size.height)
    
    cameraPreviewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
    cameraPreviewLayer?.videoGravity = AVLayerVideoGravity.resizeAspectFill
    cameraPreviewLayer?.connection?.videoOrientation = AVCaptureVideoOrientation.portrait
    cameraPreviewLayer?.frame = layer.bounds
    
    self.layer.insertSublayer(cameraPreviewLayer!, at: 0)
  }
  
  func setupInputOutput() {
      do {
          let caputureDeviceInput = try AVCaptureDeviceInput(device: currentDevice!)
          
          captureSession.addInput(caputureDeviceInput)
          
          photoOutput = AVCapturePhotoOutput()
          
          let outPutPhotoSettings = [AVCapturePhotoSettings(format: [AVVideoCodecKey: AVVideoCodecType.jpeg])]
          photoOutput!.setPreparedPhotoSettingsArray(outPutPhotoSettings, completionHandler: nil)
          captureSession.addOutput(photoOutput!)
      } catch {
          print(error)
      }
  }
  
  func setupDevice () {
      let deviceDiscoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [AVCaptureDevice.DeviceType.builtInWideAngleCamera], mediaType: AVMediaType.video, position: AVCaptureDevice.Position.unspecified)
      
      let devices = deviceDiscoverySession.devices
      
      for device in devices {
          if device.position == AVCaptureDevice.Position.back {
              mainCamera = device
          } else if device.position == AVCaptureDevice.Position.front {
              innerCamera = device
          }
      }
    currentDevice = mainCamera
  }
  
  func setupCaptureSession() {
    captureSession.sessionPreset = AVCaptureSession.Preset.photo
  }
  
  // UIViewã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã¯å¿…é ˆ
  required init?(coder _: NSCoder) {
    fatalError("init(coder:) is not implemented.")
  }
}

extension CameraView: AVCapturePhotoCaptureDelegate {
  func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
    if let imageData = photo.fileDataRepresentation() {
      let uiImage = UIImage(data: imageData)
      UIImageWriteToSavedPhotosAlbum(uiImage!, nil, nil, nil)
    }
  }
}
